#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Base classes and useful functionality for implementing :class:`interfaces.IContentUnitRepresentationBatchConverter`
objects.

$Id$
"""
from __future__ import print_function, unicode_literals, absolute_import, division
__docformat__ = "restructuredtext en"

logger = __import__('logging').getLogger(__name__)

import os
import re
import six
import sys
import time
import shutil
import tempfile
import subprocess

try:
	from cStringIO import StringIO
except ImportError:
	from StringIO import StringIO

from zope import interface

from plasTeX.Imagers import WorkingFile
from plasTeX.Filenames import Filenames

from nti.contentrendering import ConcurrentExecutor as ProcessPoolExecutor

from . import interfaces

_marker = object()
logger = __import__('logging').getLogger(__name__)

@interface.implementer(interfaces.IContentUnitRepresentationBatchConverter)
class AbstractContentUnitRepresentationBatchConverter(object):
	"""
	Implements batch conversion of resources by acting as a wrapper
	to drive an object that can compile and transform a batch of resources at once.
	"""

	_final_methods = ('storeKeys','createResourceSetGenerator',
					   'generateResources', 'storeResources', 'canGenerate',
					   '_prepare_compile_driver_with_sources')

	def __new__(cls, document, *args, **kwargs):
		self = super(AbstractContentUnitRepresentationBatchConverter,cls).__new__(cls, document)
		for final in AbstractContentUnitRepresentationBatchConverter._final_methods:
			if getattr( self, final ) is not getattr( AbstractContentUnitRepresentationBatchConverter, final ):
				raise ValueError( "Cannot override deprecated method %s" % final ) #pragma: no cover
		return self

	def __init__(self, document):
		self.document = document
		self.batch_args = ()
		self.batch_kwargs = {}
		self._batch_drivers = []


	def _new_batch_converter_driver(self, *args, **kwargs):
		"""
		Returns an object with a `convert_batch(generatable_content_units)` method used to handle
		a batch conversion. (See :func:`AbstractCompilingContentUnitRepresentationBatchConverter.convert_batch`).

		This class will pass the values of `self.batch_args` and `self.batch_kwargs` to this
		method.
		"""
		raise NotImplementedError # pragma: no cover

	def _can_process( self, content_unit ):
		return True

	def process_batch( self, content_units ):

		generatable_units = [s for s in content_units if self._can_process( s )]
		if len(generatable_units) != len(content_units):
			logger.warn( "Given sources that cannot be generated by this object" )

		size = len(generatable_units)
		if not size > 0:
			return ()

		driver = self._new_batch_converter_driver( *self.batch_args, **self.batch_kwargs )
		if driver is not self:
			self._batch_drivers.append(driver)

		return driver.convert_batch( generatable_units )


	def close(self):
		for driver in self._batch_drivers:
			try:
				driver.close()
			except AttributeError:
				pass
		self._batch_drivers = []

@interface.implementer(interfaces.IContentUnitRepresentationBatchCompilingConverter)
class AbstractCompilingContentUnitRepresentationBatchConverter(AbstractContentUnitRepresentationBatchConverter):
	"""
	Implements batch conversion of resources by acting as a wrapper
	to drive an object (a :class:`AbstractDocumentCompilerDriver`) that can compile and
	transform a batch of resources at once.
	"""

	compiler = ''
	debug = False

	def __init__(self, document):
		super(AbstractCompilingContentUnitRepresentationBatchConverter,self).__init__(document)
		self._compiler_drivers = []

	def _new_batch_converter_driver(self, *args, **kwargs ):
		return self

	def _new_batch_compile_driver( self, document, *args, **kwargs ):
		raise NotImplementedError  # pragma: no cover

	def _prepare_compile_driver_with_content_units( self, content_units ):
		"""
		Responsible for adding the generators used to ``_compiler_drivers``
		"""
		encoding = self.document.config['files']['input-encoding']
		generator = self._new_batch_compile_driver( self.document, compiler=self.compiler, encoding=encoding)
		self._compiler_drivers.append(generator)
		generator.writePreamble()
		for unit in content_units:
			generator.add_content_unit_to_batch(unit)
		generator.writePostamble()
		return generator


	def convert_batch( self, content_units ):
		"""
		:param content_units: The units of content (e.g., plasTeX DOM Node objects)
			that we are to convert. We assume that it has already been established
			that they can be converted.
		"""
		generator = self._prepare_compile_driver_with_content_units( content_units )

		return generator.compile_batch_to_representations()

	def close(self):
		super(AbstractCompilingContentUnitRepresentationBatchConverter,self).close()
		for generator in self._compiler_drivers:
			try:
				generator.close()
			except AttributeError:
				pass
		self._compiler_drivers = []

class AbstractConcurrentCompilingContentUnitRepresentationBatchConverter(AbstractCompilingContentUnitRepresentationBatchConverter):
	"""
	Exists to add concurrency support to a compilation process.
	"""
	concurrency = 1


	def convert_batch( self, content_units ):
		if self.concurrency == 1 or len(content_units) == 1:
			return super(AbstractConcurrentCompilingContentUnitRepresentationBatchConverter,self).convert_batch( content_units )

		chunks = [[] for _ in range(self.concurrency)]
		for i, unit in enumerate(content_units):
			chunks[i % self.concurrency].append( unit )

		generators = [self._prepare_compile_driver_with_content_units( chunk ) for chunk in chunks]
		results = []
		params = [True] * self.concurrency

		with ProcessPoolExecutor() as executor:
			for resources in executor.map(_processBatchSource, generators, params):
				results.extend( resources )

		return results


class AbstractConcurrentConditionalCompilingContentUnitRepresentationBatchConverter(AbstractConcurrentCompilingContentUnitRepresentationBatchConverter):
	"""
	Extends the generic concurrent compilation process by implementing the :meth:`_can_process`
	method. By default, checks the contents of `illegalCommands` as a sequence of regular expressions
	against each source; if it matches, it cannot be processed.
	"""

	illegalCommands	= ()

	def _can_process(self, content_unit):
		if not self.illegalCommands:
			return True

		source = content_unit.source
		for command in self.illegalCommands:
			if re.search(command, source):
				return False
		return True


def _processBatchSource(generator, params, raise_exceptions=False):
	"""
	:param bool raise_exceptions: When called an a concurrent.futures pool,
		then exceptions from the job method (this method) can cause the pool
		to hang. If ``False`` (the default), then this method will swallow
		exceptions.
	"""
	try:
		if generator.size() > 0:
			return generator.compile_batch_to_representations()
	except Exception:
		# Running in a concurrent.futures, throwing tends to
		# hang the pool.
		# NOTE that the pool we usually use now does not have that problem.
		# however, we want to customize the return value so as not to cause
		# further problems.
		if raise_exceptions:
			raise
		from zope.exceptions import print_exception
		t, v, tb = sys.exc_info()
		print_exception(t, v, tb, with_filenames=False)

	return ()

for _x in AbstractContentUnitRepresentationBatchConverter._final_methods:
	setattr( AbstractContentUnitRepresentationBatchConverter, _x, _marker )

class AbstractDocumentCompilerDriver(object):
	"""
	Accumulates resources into a single document which is compiled as a file;
	the compiler is expected to produce output files is that same directory.
	"""

	document_filename = 'resources'
	document_extension = 'tex'
	compiler = None

	def __init__(self, document, compiler='', encoding='utf-8', batch=0, **kwargs):
		self._document = document
		self._batch = batch
		self._writer = StringIO()
		if compiler:
			self.compiler = compiler
		self._encoding = encoding
		self._generatables = list()
		self._delete_paths = list()

	def __getstate__(self):
		# In concurrency, we need to be pickled. The plasTeX document
		# does not support this, and neither do cStringIO objects
		d = dict(self.__dict__)
		# So we drop the document, which we won't access at all anymore
		d['_document'] = None
		# And we convert the string io object into a plain string; we will
		# read from it but not write to it anymore
		d['_writer'] = self.source_bytes()
		return d

	def size(self):
		return len(self._generatables)

	def writePreamble(self):
		pass #pragma: no cover

	def writePostamble(self):
		pass #pragma: no cover

	def _compilation_source_for_content_unit( self, content_unit ):
		"""
		Called to determine the source text (string) that represents the
		content unit during compilation. This implementation returns the
		`source` attribute of the given object (e.g., a :class:`plasTeX.DOM.Node`
		defines that attribute to return the TeX code to create that node).

		This is the appropriate place to add any wrapping or additional information that
		should be used during compilation of this unit.
		"""
		return content_unit.source

	def add_content_unit_to_batch(self, content_unit):
		# Recall that we cannot keep a proper reference to Node objects
		# during pickling. So we save the source only.
		# NOTE: Some of our subclasses are doing unholy things:
		# The ResourceDB lets us return a ContentRepresentation, which includes
		# the source used to generate it. That must match the source of the Node object
		# from the DOM in order for it to be found. Our subclasses depend on us
		# to track, in order, the original source (not the compiled source)
		self._generatables.append( content_unit.source )
		self.writeResource( self._compilation_source_for_content_unit( content_unit ) )

	def writeResource(self, source):
		self.write( source )

	def compile_batch_to_representations(self):
		start = time.time()

		workdir = self.compileSource()

		resources = self.create_resources_from_compiled_directory(workdir)
		nresources = len(resources)

		if nresources != len(self._generatables): # pragma: no cover
			logger.warn( 'Expected %s files but only generated %s for batch %s',
						 len(self._generatables), nresources, self._batch )

		elapsed = time.time() - start
		logger.info( "%s resources generated in %ss for batch %s", nresources, elapsed, self._batch )

		return resources

	def _run_compiler_on_file( self, filename ):
		"""
		:return: The exit status of the command.
		:raise subprocess.CalledProcessError: If the command fails
		"""
		# Run the compiler
		program = self.compiler
		# XXX This is fairly dangerous!
		#return os.system(r"%s %s" % (program, filename))
		return subprocess.check_call( (program, filename) )
		#JAM: This does not work. Fails to read input
		# cmd = str('%s %s' % (program, filename))
		# print shlex.split(cmd)
		# p = subprocess.Popen(shlex.split(cmd),
		# 			 stdout=subprocess.PIPE,
		# 			 stderr=subprocess.STDOUT,
		# 			 )
		# while True:
		# 	line = p.stdout.readline()
		# 	done = p.poll()
		# 	if line:
		# 		imagelogger.info(str(line.strip()))
		# 	elif done is not None:
		# 		break



	def compileSource(self):
		"""
		Writes the accumulated document to a file in a temporary directory, and then
		runs the compiler.
		:return: The name of the temporary directory.
		"""

		# Make a temporary directory to work in
		tempdir = tempfile.mkdtemp()
		self._delete_paths.append(tempdir)

		filename = os.path.join(tempdir, self.document_filename + '.' + self.document_extension )

		source_bytes = self.source_bytes()
		__traceback_info__ = tempdir, filename, source_bytes
		assert isinstance(source_bytes, bytes) # already encoded


		with open( filename, 'wb' ) as out:
			out.write(source_bytes)

		try:
			self._run_compiler_on_file( filename )
		except:
			# TODO: See Imagers/__init__.py. Can we get log file info here?
			shutil.rmtree( tempdir, True ) # Try to clean up
			raise

		return tempdir


	def create_resources_from_compiled_directory(self, workdir):
		"""
		Given the directory in which the document was compiled,
		collect and return the generated resources.
		"""
		raise NotImplementedError( "Creating resources from compiled directory" ) #pragma: no cover

	def source(self):
		return self._writer

	def source_bytes(self):
		# May not be an StringIO object anymore
		try:
			result = self.source().getvalue()
		except AttributeError:
			result = self.source()

		assert isinstance(result, bytes)
		return result

	def write(self, data):
		"Given a text or bytes object, record its bytes, encoding with this object's encoding"
		if data:
			# In py2, pure python StringIO objects support arbitrary
			# mixing of unicode and bytes objects, automatically *decoding*
			# the bytes portions to unicode and returning a unicode object
			# when 'getvalue' is called.
			# However, cStringIO objects are actually strict about
			# requiring every input being bytes, immediately *encoding*
			# any unicode objects to bytes using the default encoding.
			# This can easily produce UnicodeEncodeErrors.
			# Therefore, we pre-emptively encode ourself to work the same
			# no matter what
			if isinstance(data, six.text_type):
				data = data.encode(self._encoding)

			self._writer.write(data)

	def close(self):
		for p in self._delete_paths:
			shutil.rmtree(p, True)
		self._delete_paths = []


class AbstractOneOutputDocumentCompilerDriver(AbstractDocumentCompilerDriver):
	"""
	Assumes the compiler creates one output document, looks for, and converts that.

	The output document is looked for based on the compiler document filename
	plus any one of the `output_extensions`.
	"""

	output_extensions = ('dvi','pdf','ps','xml') # The defaults are setup for tex

	def create_resources_from_compiled_directory(self, tempdir):

		output = None
		for ext in self.output_extensions:
			fname = self.document_filename + '.' + ext
			fpath = os.path.join(tempdir, fname)
			if os.path.isfile(fpath):
				output = WorkingFile(fpath, 'rb', tempdir=tempdir)
				break

		if output is None: # pragma: no cover
			__traceback_info__ = (self, tempdir, self.output_extensions)
			raise ValueError( "Compiler did not produce any output" )

		return self.convert(output, tempdir)

	def convert(self, output, workdir):
		"""
		Convert output to resources.
		:param output: An open file. When this file is closed, the temp directory will be deleted.
		:param workdir: The directory used by the compiler.
		:return: A sequence of content representation objects (resources).
		"""
		__traceback_info__ = self # pragma: no cover
		raise NotImplementedError # pragma: no cover

class AbstractLatexCompilerDriver(AbstractOneOutputDocumentCompilerDriver):
	"""
	Drives a compiler that takes latex input.
	"""

	interaction_mode = r'\batchmode'

	def writePreamble(self):
		self.write(self.interaction_mode)
		self.write( '\n' )

		self.write(getattr(self._document.preamble, 'source', self._document.preamble))
		self.write('\\makeatletter\\oddsidemargin -0.25in\\evensidemargin -0.25in\n')
		self.write('\\begin{document}\n')

	def writePostamble(self):
		self.write('\n\\end{document}\\endinput')

	def writeResource(self, source):
		self.write('%s\n%s\n' % ('', source))

class ImagerContentUnitRepresentationBatchConverterDriver(object):

	def __init__(self, imager, resourceType):
		self.imager = imager
		self.resourceType = resourceType

	def convert_batch(self, content_units):
		images = []
		for unit in content_units:
			source = unit.source

			new_image = self.imager.getImage(unit)
			if not interfaces.IContentUnitRepresentation.providedBy( new_image ):
				interface.alsoProvides( new_image, interfaces.IFilesystemContentUnitRepresentation )
				new_image.source = source
				new_image.qualifiers = ()
				new_image.resourceType = self.resourceType
				new_image.resourceSet = None
			images.append( new_image )

		self.imager.close()

		return images


class ImagerContentUnitRepresentationBatchConverter(AbstractContentUnitRepresentationBatchConverter):
	"""
	A batch converter that delegates to a plasTeX :class:`plasTeX.Imagers.Imager` object.

	Note that at this time, this object does not add concurrency. If concurrency is desired, it
	must be implemented integral to the imager.
	"""

	concurrency = 1
	imagerClass = None

	def __init__(self, document, imagerClass):
		super(ImagerContentUnitRepresentationBatchConverter, self).__init__(document)

		self.imagerClass = imagerClass
		if getattr(self.imagerClass,'resourceType', None):
			self.resourceType = self.imagerClass.resourceType
		else:
			self.resourceType = self.imagerClass.fileExtension[1:]

		self._imager_paths = list()

	def _new_batch_converter_driver(self, *args, **kwargs ):
		return ImagerContentUnitRepresentationBatchConverterDriver(self.createImager(), self.resourceType)

	def createImager(self):
		newImager = self.imagerClass(self.document)

		# create a tempdir for the imager to write images to
		tempdir = tempfile.mkdtemp()
		newImager.newFilename = Filenames(os.path.join(tempdir, 'img-$num(12)'),
										  extension=newImager.fileExtension)

		newImager._filecache = os.path.join(os.path.join(tempdir, '.cache'),
											newImager.__class__.__name__+'.images')

		return newImager

	def close(self):
		super(ImagerContentUnitRepresentationBatchConverter,self).close()
		for p in self._imager_paths:
			shutil.rmtree(p, True)
		self._imager_paths = []
